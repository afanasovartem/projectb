1. Анализ данных в Python (pandas и numpy)
Загрузить датасет в формате CSV и выполнить полный анализ данных. Минимальные требования:

A. Загрузка и первичный обзор
загрузить данные через pandas;

вывести первые/последние строки;

посмотреть структуру данных;

проверить типы данных и при необходимости привести их к корректным типам.

B. Обработка данных
Нужно выполнить::

Пропущенные значения

найти пропуски (isnull, isna);

посчитать количество пропусков по столбцам;

выбрать стратегию заполнения или удаления:

удаление строк/столбцов;

заполнение медианой/средним/модой/значениями по группам.

Дубликаты

найти дубликаты (duplicated);

вывести количество дублирующихся строк;

удалить их при необходимости (drop_duplicates).

Выбросы (при необходимости)

с помощью z-score из numpy;

визуально (boxplot).

Статистики данных:
описательная статистика (describe);

подсчёт уникальных значений, частоты;

корреляционный анализ (corr).

C. Визуализация данных
Нужно построить минимум 5 графиков:

гистограммы распределений;

линейный график;

столбчатые диаграммы;

boxplot;

heatmap корреляций.

Можно использовать:
matplotlib, seaborn, plotly.

D. Группировки и агрегации
Нужно применить группировки (groupby) и выполнить минимум 3 вида агрегаций:

Примеры:

среднее / медиана по группам;

подсчёт количества;

суммирование;

построение сводной таблицы (pivot_table).

2. Аналитика в Yandex DataLens
Необходимо:

Загрузить датасет в Datalens.

Создать минимум 3 чарта:

диаграмма по категориям,

линейный график,

таблица или карта (если есть геоданные).

Создать дашборд минимум из 3 визуализаций.

Настроить:

фильтры,

селекторы,

интерактивность графиков.

3. Публикация проекта на GitHub
Нужно

Создать публичный репозиторий.

Добавить:

Jupyter Notebook (.ipynb) с анализом;

исходный CSV-датасет;

README.md с описанием проекта.

Сделать минимум два коммита:

первый — загрузка исходных данных и структуры проекта;

второй — финальный анализ и визуализации.

